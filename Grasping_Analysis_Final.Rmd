---
title: "Grasping_Task_Analysis"
author: "Zeynep Bolluk, Rowan Mohamed, Esma Sakalli, Katharina Trant"
date: "2023-12-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```



```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(sjPlot)
library(gridExtra)
library(EnvStats)
library(outliers)
library(lme4)
library(lmerTest) # significance testing for linear mixed models
```

## Importing Data 

```{r}
# Set working directory to the folder containing the CSV files
setwd("C:/Users/Dell/Desktop/Courses/StudyProject/analysis/graspingTask")

# load the data from the cloud
combined_data <- read.csv("combined.csv")

# Create inverted %in% function
`%ni%` <- Negate(`%in%`)

# fix the participant id
combined_data <- combined_data %>% group_by(participant_id) %>% mutate(participant_id = cur_group_id())

# Reorder columns putting 'participant_id' at the beginning
combined_data <- combined_data[, c("participant_id", setdiff(names(combined_data), "participant_id"))]

# Cast column types from factor to numeric/char
combined_data$time <- as.numeric(as.character(combined_data$time))
combined_data$num_instructions <- as.numeric(as.character(combined_data$num_instructions))
combined_data$location <- as.character(combined_data$location)
combined_data$block <- as.numeric(as.character(combined_data$block))

# Convert 'condition' and 'success' variables to a categorical variable (factor)
combined_data$condition <- factor(combined_data$condition)
combined_data$success <- factor(combined_data$success)

# Check the structure of the merged data
str(combined_data)

# View summary statistics
summary(combined_data) 
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

##Outlier Detection

```{r pressure, echo=FALSE}

# Checking for missing values
missing_values <- colSums(is.na(combined_data))
print(missing_values)

# log transformation
combined_data$logTime <- log(combined_data$time)

# Grubbs' test by condition
grubbs_results_log <- by(combined_data$logTime, combined_data$condition, grubbs.test)
print(grubbs_results_log)

#visuals
ggplot(combined_data, aes(x = condition, y = logTime)) +
  geom_boxplot() +
  labs(title = "Distribution of log-transformed times by condition")


#Even though the result for Auditory condition is significant, and Grubbs test indicates that '18.33502' is an outlier, we decided to no exclude this data after checking the plot

```


## Normality assumption check

```{r}
# Split the data by condition and drop fails
auditory_data <- combined_data %>% filter(condition == "auditory", success == "success")
tactile_data <- combined_data %>% filter(condition == "tactile", success == "success")

# Check for normality using histogram and normal probability plot for each condition
par(mfrow=c(2,2)) # create 2x2 plot grid

# Histogram and normal probability plot for auditory condition
hist(auditory_data$time, main="Histogram of Auditory Times", xlab="Times")
qqnorm(auditory_data$time, main="Normal Probability Plot of Auditory Times")
qqline(auditory_data$time)

# Histogram and normal probability plot for tactile condition
hist(tactile_data$time, main="Histogram of Tactile Times", xlab="Times")
qqnorm(tactile_data$time, main="Normal Probability Plot of Tactile Times")
qqline(tactile_data$time)

# normal distribution
x <- seq(min(log(tactile_data$time)), max(log(tactile_data$time)), length.out = length(tactile_data$time))
y <- dnorm(x, mean = mean(log(tactile_data$time)), sd = sd(log(tactile_data$time)))
t_normal <- data.frame(x = x, y = y)

x <- seq(min(log(auditory_data$time)), max(log(auditory_data$time)), length.out = length(auditory_data$time))
y <- dnorm(x, mean = mean(log(auditory_data$time)), sd = sd(log(auditory_data$time)))
a_normal <- data.frame(x = x, y = y)

# plot density comparisons for t and a (justification for parametric LMM)
normalityAssumptionforTactile <- ggplot(tactile_data) + 
  geom_density(aes(x = log(time)), fill = "red", alpha = 0.5) +
  geom_line(aes(x = t_normal$x, y = t_normal$y), size = 0.7, color = "darkgreen") +
  labs(
    title = "Normality Assumption for Tactile",
    x = "Log-transformed Time",
    y = "Tactile Normality")

normalityAssumptionforAuditory <- ggplot(auditory_data) + 
  geom_density(aes(x = log(time)), fill = "red", alpha = 0.5) +
  geom_line(aes(x = a_normal$x, y = a_normal$y), size = 0.7, color = "darkgreen") +
  labs(
    title = "Normality Assumption for Auditory",
    x = "Log-transformed Time",
    y = "Auditory Normality")

normalityAssumptionforTactile
normalityAssumptionforAuditory

ggsave("normalityAssumptionforAuditory.png", plot = normalityAssumptionforAuditory, dpi = 600)

ggsave("normalityAssumptionforTactile.png", plot = normalityAssumptionforTactile, dpi = 600)

```

```{r, eval=FALSE, include=FALSE}
# Perform Shapiro-Wilk test for normality for each condition
shapiro.test(auditory_data$time)
shapiro.test(tactile_data$time)


# Perform Kolmogorov-Smirnov test for each condition (compares data to normal distribution pnorm)
ks.test(auditory_data$time, "pnorm", mean(auditory_data$time), sd(auditory_data$time))
ks.test(tactile_data$time, "pnorm", mean(tactile_data$time), sd(tactile_data$time))

#the results state that the data doesn't follow the normal distribution
```

Looks multi-modal because of different number of instructions.

```{r}
# Assumption: tri-modality of the data for different number of commands
aud_1 <- combined_data %>% filter(condition == "auditory", success == "success", num_instructions == 1)
aud_2 <- combined_data %>% filter(condition == "auditory", success == "success", num_instructions == 2)
aud_3 <- combined_data %>% filter(condition == "auditory", success == "success", num_instructions == 3)

tac_1 <- combined_data %>% filter(condition == "tactile", success == "success", num_instructions == 1)
tac_2 <- combined_data %>% filter(condition == "tactile", success == "success", num_instructions == 2)
tac_3 <- combined_data %>% filter(condition == "tactile", success == "success", num_instructions == 3)

# plot density comparisons filtered by number of commands
compare_to_normal <- function(data) {
  x <- seq(min(data$time), max(data$time), length.out = length(data$time))
  y <- dnorm(x, mean = mean(data$time), sd = sd(data$time))
  t_normal <- data.frame(x = x, y = y)
  
  p <- ggplot(data) + 
    geom_density(aes(x = time), fill = "red", alpha = 0.5) +
    geom_line(aes(x = t_normal$x, y = t_normal$y), size = 0.7, color = "darkgreen") +
    ggtitle(sprintf("data: %s", deparse(substitute(data))))
  
  return(p)
}

#aud1 <- compare_to_normal(aud_1) -> it's zero, so no need to check
aud2 <- compare_to_normal(aud_2)
aud3 <- compare_to_normal(aud_3)

#tac1 <- compare_to_normal(tac_1) -> it's zero, so no need to check
tac2 <- compare_to_normal(tac_2)
tac3 <- compare_to_normal(tac_3)

grid.arrange(aud2,aud3,tac2,tac3, ncol = 2)

#ggsave(paste0(SAVE,"normality.png"), plot = grid, dpi = 600)
#No tri-modality is detected
```
```{r, eval=FALSE, include=FALSE}
# Statistical test
#shapiro.test(log(aud_1$time))
shapiro.test(log(aud_2$time))
shapiro.test(log(aud_3$time))

#shapiro.test(log(tac_1$time))
shapiro.test(log(tac_2$time))
shapiro.test(log(tac_3$time))
```

Statistical tests suggest non-normality, visually they are normally distributed. The t-test and Wilcoxon rank sum test yield the same results in all comparisons, so we go with the student's t-test and assume that the data stems from a normal distribution.

# Data visualisation and hypothesis testing

Calculate summary statistics, visualize aspects of the data and test the corresponding hypotheses.

## Trial times per participant

```{r}
# time standard devs
combined_data %>% group_by(condition) %>% summarize(mean = mean(time), sd = sd(time))
combined_data %>% group_by(condition, block) %>% summarize(mean = mean(time), sd = sd(time))
```

```{r}
tact_vs_audi_per_participant <- combined_data %>% 
  filter(success == "success") %>% 
  group_by(participant_id, condition) %>% 
  summarize(mean_time = mean(time) * 1000) %>% 
  spread(condition, mean_time) %>% 
  mutate(diff = tactile - auditory, color = ifelse(diff > 0, "#00BFC4", "#F8766D")) %>% 
  ggplot(aes(x = factor(participant_id), y = diff, fill = color)) +
  geom_bar(stat = "identity", position = "identity") +
  labs(
    title = "Mean trial time difference between conditions per participant",
    x = "\n Participant",
    y = "Trial time difference (ms) \n") +
  theme_linedraw() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5), axis.text.x = element_text(size = 6),
    legend.position = "right") +
  scale_fill_manual(name=NULL, values = c("#00BFC4", "#F8766D"), labels = c("Tactile > Auditory", "Auditory > Tactile"))

tact_vs_audi_per_participant
ggsave("tact_vs_audi_per_participant.png", plot = tact_vs_audi_per_participant, dpi = 600)
```

```{r}
# Barplot: Mean trial times for each condition per participant
combined_data %>% filter(success == "success") %>% group_by(participant_id, condition) %>% summarize(mean_time = mean(time)*1000)

times_per_participant <- combined_data %>% 
  filter(success == "success") %>% 
  group_by(participant_id, condition) %>% 
  summarize(mean_time = mean(time)*1000) %>% 
  ggplot(aes(x = factor(participant_id), y = mean_time, fill = condition)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Mean trial times for each participant per condition", 
    x = "Participant", 
    y = "Trial time (ms) \n",
    fill = "condition"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold", hjust = 0.5), 
    plot.subtitle = element_text(hjust = 0.3),
    legend.position = "right", axis.text.x = element_text(size = 6))

times_per_participant
ggsave("times_per_participant.png", plot = times_per_participant, dpi = 600)
```

## Trial times per condition

```{r}
# Violin plot: x = condition, y = RT
combined_data %>% group_by(condition) %>% filter(success == "success") %>% summarize(mean_time = mean(time)*1000)
times_condition_violin <- combined_data %>% filter(success == "success") %>%
  ggplot(aes(x = condition, y = time*1000)) +
  geom_violin(width=0.5) +
  geom_boxplot(outlier.shape = NA, width=0.1) +
  labs(
    title = "Distribution of trial times per condition", 
    x = NULL, 
    y = "Trial time (ms) \n"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold"), legend.position = "right", legend.title = element_blank()) +
  scale_y_continuous(limits = c(0, 12000)) # remove outliers from plot

times_condition_violin

ggsave("times_condition_violin_blind.png", plot = times_condition_violin, dpi = 600)
  

# Perform t-test (with unpaired data as fail trials are excluded) test to compare group means
t.test(auditory_data$time, tactile_data$time, paired = FALSE)
```

```{r 'compare the learning effect'}
# Line plot: x = block (grouped by condition --> 2 lines), y = median/mean RT
combined_data %>% group_by(block, condition) %>% summarize(mean_time = mean(time)*1000)
times_per_block <- combined_data %>% group_by(block, condition) %>% summarize(mean_time = mean(time)*1000) %>% 
  ggplot(aes(x = block, y = mean_time, color=condition)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Mean trial times per block by condition", 
    x = "\n Block number", 
    y = "Mean trial times (ms) \n"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold"), legend.position = "right", legend.title = element_blank()) +
  scale_x_continuous(breaks = c(1:8)) +
  scale_y_continuous(limits = c(0, 6000))

times_per_block
ggsave("times_per_block.png", plot = times_per_block, dpi = 600)

# test diffs between blocks -> We can observe a small effect of learning in the first block. However, the mean differences between blocks are not big (especially, compared to blindfolded participants). So, we decided to keep the data for block 1 for the analysis, and treat localization task as training.  

```

```{r}
# Barplot: y = RT, x = fruit position
pos_data <- combined_data # dummy
pos_data$location[pos_data$location == "rep_1"] = "1"
pos_data$location[pos_data$location == "rep_2"] = "2"
pos_data$location[pos_data$location == "rep_3"] = "3"
pos_data$location[pos_data$location == "rep_4"] = "4"
pos_data$location[pos_data$location == "rep_5"] = "5"
pos_data$location[pos_data$location == "rep_6"] = "6"
pos_data$location[pos_data$location == "rep_7"] = "7"
pos_data$location[pos_data$location == "rep_8"] = "8"
pos_data$location[pos_data$location == "rep_9"] = "9"


pos_data %>% filter(success == "success") %>% group_by(condition, location) %>% summarize(mean_time = mean(time)*1000)
pos_data %>% filter(success == "success") %>% group_by(condition, location) %>% summarize(mean_time = mean(time)*1000) %>%
  ggplot(aes(x = location, y = mean_time, fill = condition)) +
  geom_bar(stat="identity", position = "dodge") +
  labs(
    title = "Mean trial time per fruit location by condition", 
    x = "\n Fruit position", 
    y = "Mean trial time (ms) \n"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold", hjust = 0.5), 
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "right")


# mid (5) fastest as starting point is in front
# one-command positions up (2), left (4), right (6), down (8) are shorter than two-command positions
# diff between conditions for positions 1 and 3 (upper left and right) greater than for 7 and 9 (lower left and right)
# --> grasping at top shelf took longer, probably the chair was too low

# Could add test for each fruit position comparing conditions
# Could add comparison between upper left (1) and upper right (3) and/or lower left (7) and lower right (9)
```

## Fails by condition

```{r}
# Bar plot: x = fail, exfail (grouped by condition), y = counts
combined_data %>% group_by(condition, success) %>% count() %>% filter(success != "success")
combined_data %>% group_by(condition, success) %>% count() %>% filter(success != "success") %>%
  ggplot(aes(x = condition, y = n, fill = success)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = n), position = position_dodge(width = 1), vjust = 2, hjust=0.5) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  labs(
    title = "Count of trials with false instruction or response", 
    x = NULL, 
    y = "Count \n",
    subtitle = "in auditory and tactile condition \n"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold", hjust = 0.5), 
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "right", legend.title = element_blank()) +
  scale_fill_discrete(labels = c("experimenter fail", "participant fail"))
```

```{r}
# Line plot: x = block (grouped by condition --> 2 lines), y = fail counts
combined_data %>% group_by(block, condition) %>% summarize(fail_count = sum(success == "fail"), exFail_count = sum(success == "exFail"))
fails_per_block <- combined_data %>% group_by(block, condition) %>% summarize(fail_count = sum(success == "fail"), exFail_count = sum(success == "exFail")) %>% 
  ggplot(aes(x = block, y = fail_count, color=condition)) +
  geom_point(aes(y = fail_count, shape="Group 1"), size=3) +
  geom_line(aes(y = fail_count)) +
  geom_point(aes(y = exFail_count, shape="Group 2"), size=3) +
  geom_line(aes(y = exFail_count)) +
  labs(
    title = "Count of trials with false response or instruction per block by condition", 
    x = "\n Block number", 
    y = "Fail count \n"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold"), legend.position = "right", legend.title = element_blank()) +
  scale_x_continuous(breaks = c(1:8)) +
  scale_shape_manual(
    name = "Fail type",
    values = c("Group 1" = 16, "Group 2" = 5),  # Use 16 for a solid point
    labels = c("Participant fails", "Experimenter fails"))

fails_per_block
ggsave("fails_per_block_blind.png", plot = fails_per_block, dpi = 600)

# test for significance
fails_a <- combined_data %>% group_by(block, condition) %>% summarize(fail_count = sum(success == "fail")) %>% filter(condition=="auditory")
fails_t <- combined_data %>% group_by(block, condition) %>% summarize(fail_count = sum(success == "fail")) %>% filter(condition=="tactile")

t.test(fails_a$fail_count, fails_t$fail_count)

fails_time <- combined_data %>% group_by(block, condition) %>% summarize(fail_count = sum(success == "fail"), mean_time = mean(time)) %>% filter(condition=="tactile")
cor.test(fails_time$mean_time, fails_time$fail_count)
```


# Linear Mixed-Effects Model (LMM)

## Data preparation

```{r}
grasping_data <- combined_data %>% filter(success == "success") %>% select(-success)

# rename repetition locations in df
grasping_data$location[grasping_data$location == "rep_1"] = "1"
grasping_data$location[grasping_data$location == "rep_2"] = "2"
grasping_data$location[grasping_data$location == "rep_3"] = "3"
grasping_data$location[grasping_data$location == "rep_4"] = "4"
grasping_data$location[grasping_data$location == "rep_5"] = "5"
grasping_data$location[grasping_data$location == "rep_6"] = "6"
grasping_data$location[grasping_data$location == "rep_7"] = "7"
grasping_data$location[grasping_data$location == "rep_8"] = "8"
grasping_data$location[grasping_data$location == "rep_9"] = "9"
grasping_data$time <- grasping_data$time*1000 # s -> ms

# cast block number and number of instructions to characters
grasping_data$block <- as.character(grasping_data$block) # numeric to character for linear mixed model
grasping_data$num_instructions <- as.character(grasping_data$num_instructions)
```

## Model comparison & selection

In order to decide which variables are included in the LMM and which are excluded, we evaluate models, compare them, test for significant effects and investigate their complexity in terms of number of coefficients/parameters.

**Decision train of thought:**
- variables: num_instructions, location, block, condition, pID  
- fixed effects we are interested in: condition (difference between sensory modalities), block (learning effects)  
- In the first comparision, we decided to add 'location' as fixed effect. The model with location is significant and according to test results, it gives a little more exact information (not only instructions = 2, but also whether top-left, top-right or bottom-left, bottom-right) but makes the model drastically more complex --> In the end, because the effect can be due to the experimental settings, location is not our initial interest, and the model with location is very complex, we have decided to exclude location.

- Random effects: 
-  We've decided to add 'participant_id' as random effects to see how individual participants differ from one another and how these differences relate to the variables of interest.

- In the second comparision, we try to understand how we should approach the variability across participants in the relationship between the condition variable and time. Model_complex1 allows for this variability by including random slopes for condition, and this means that the effect of condition on time is allowed to vary across different participants. However, Model_complex3 assumes a constant effect of condition across participants, accounting for variability only through random intercepts.
-the likelihood ratio test results indicate a significant difference in fit between the two models, with model_complex1 providing a better fit compared to model_complex3. This suggests that including random slopes for condition within each participant_id improves the model's ability to capture the variability in the data. So, we've decided use model_complex1 as our final model. 

- (model comparison: anova with the likelihood ratio test (The chi-square test))  

**Resources:**
- LMM Tutorial: https://www.youtube.com/watch?v=QCqF-2E86r0 !!!  
- Interpretation explanation: https://www.youtube.com/watch?v=yJnHmCMb1q4  
- An LMM example (interaction explanation): https://www.youtube.com/watch?v=W8txfclM16U 

```{r}
# model testing: decide which variables to include/exclude (with lmerTest)

#First comparison
model_complex1 <- lmer(time ~ condition * block * (condition |participant_id ), data = grasping_data)

model_complex2 <- lmer(time ~ condition * block * location * (condition |participant_id ), data = grasping_data)


model_comparison1 <- anova(model_complex1, model_complex2, test = "Chisq")
model_comparison1

summary(model_complex1)
summary(model_complex2)

#introduction of location makes interaction effect significant, and comparision of two models by using the Likelihood Ratio Test (LRT) states that model_complex2 provides a significantly better fit to the data. However, we are not interested in location, and there is a chance that the chair was short and when people had the helmet, camera and the bracelet, it was hard for them to move. So, we will exclude 'location'
```

```{r}
#Second Model Comparison

model_complex1 <- lmer(time ~ condition * block * (condition |participant_id ), data = grasping_data)

model_complex3 <- lmer(time ~ condition * block * (1 |participant_id), data = grasping_data)


model_comparison2 <- anova(model_complex1, model_complex3, test = "Chisq")
model_comparison2

summary(model_complex1)
summary(model_complex3)

#Based on the lower AIC and BIC values, as well as the significant likelihood ratio test, model_complex1 appears to provide a better fit to the data compared to model_complex3. Therefore, model_complex1, which includes random slopes for condition, would be the preferred model for our data. This model allows for variation in the effect of condition across participants, which aligns with the theoretical framework of investigating individual differences in response to different conditions in our conditions.
```

###Final Model

```{r}
#Final lmm
model_final <- lmer(time ~
                condition + block
                + (condition | participant_id), 
              data = grasping_data)

summary(model_final)
ranef(model_final)

#Fixed Effects:
#All fixed effects (conditiontactile, block2, and block3) are significant at p < 0.05, indicating that they have a significant impact on the time taken to reach objects.

#conditiontactile: The estimated effect of the tactile condition compared to the auditory condition is 635.91, with a standard error of 201.04. This is also significant (p = 0.00298), suggesting that participants take significantly more time to reach objects in the tactile condition compared to the auditory condition.

#block2 and block3: These represent the effects of the second and third blocks of time compared to the first block. Both are significant (p < 0.001), indicating that participants take significantly less time to reach objects as the experiment progresses.

#Correlation of Fixed Effects:

#Condition (tactile) & Block 2: Correlation is not significant.

#Condition (tactile) & Block 3: Correlation is not significant.

#Block 2 & Block 3: There is a moderate positive correlation (0.5) between Block 2 and Block 3.

#Random Effects:

#Participant_id (Intercept): There is significant variability (Variance: 1693666) in the intercepts among participants, indicating individual differences in the average time taken to grab objects.

#Participant_id (Condition: tactile): Interpretation: There is significant variability (Variance: 1499195) among participants in how the tactile condition affects their performance, and this effect is moderately negatively correlated (-0.17) with the intercepts.


```


### LMM Visualizations

```{r}
#Mean Trial Times by condition

lmm_plot_meanTime <- grasping_data %>% group_by(condition) %>% summarize(mean_time = mean(time)) %>% 
  ggplot(aes(x = condition, y = mean_time, fill=condition)) + geom_bar(stat = "identity") +
  labs(
    title = "Mean trial times by condition", 
    x = "Condition Type", 
    y = "Mean trial times (ms) \n"
    ) +
  theme_linedraw() + 
  theme(plot.title = element_text(face = "bold"), legend.position = "right", legend.title = element_blank()) +
  scale_y_continuous(limits = c(0, 6000))

lmm_plot_meanTime


ggsave("lmm_plot_meanTime.png", plot = lmm_plot_meanTime, dpi = 600)
```


```{r}

library(emmeans)

# Interaction Plot
interaction_data <- grasping_data %>%
  mutate(block = factor(block)) %>%
  group_by(condition, block) %>%
  summarize(mean_time = mean(time)) 

lmm_plot_interaction <- ggplot(interaction_data, aes(x = condition, y = mean_time, color = block, group = block)) +
  geom_line() +
  geom_point(size = 3) +
  labs(title = "Interaction Plot", x = "Condition", y = "Mean Time", color = "Block") +
  theme_minimal()

lmm_plot_interaction


## Interaction Plot with error bars
interaction_data <- grasping_data %>%
  mutate(block = factor(block)) %>%
  group_by(condition, block) %>%
  summarize(mean_time = mean(time),
            sd_time = sd(time), # Standard deviation of time
            n = n())           # Number of observations

interaction_data$se_time <- interaction_data$sd_time / sqrt(interaction_data$n) # Standard error of time


lmm_plot_interaction_errorbars <- ggplot(interaction_data, aes(x = condition, y = mean_time, color = block, group = block)) +
  geom_line() +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_time - se_time, ymax = mean_time + se_time), width = 0.1) +
  labs(title = "Interaction Plot with Error Bars", x = "Condition", y = "Mean Time", color = "Block") +
  theme_minimal()

lmm_plot_interaction_errorbars

ggsave("lmm_plot_interaction_errorbars.pdf", plot = lmm_plot_interaction_errorbars, dpi = 600)

#The lines are not parallel and cross each other, it suggests an interaction effect. Thus, the effect of condition on mean time differs depending on the level of block. Block 2 has more steeper slope, suggesting that the effect of condition on mean time is stronger in Block 2 compared to Block 3.

#The error bars around each point on the lines represent the variability or uncertainty in the mean time estimate for each condition and block combination. The length of the error bars indicates the magnitude of the variability or uncertainty. Longer error bars suggest greater variability or uncertainty in the mean time estimate. -> In general, error bars are longer for tactile condition, block1>block2>block3
```


```{r}

#Categorical Plot

lmm_categorical_plot <- ggplot(grasping_data, aes(x = condition, y = time, fill = factor(block))) +
  geom_boxplot(alpha = 0.7, color = "black") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightyellow")) +  # Add another color for the third level
  theme_minimal() +
  labs(title = "Categorical Plot", x = "Condition", y = "Time")

lmm_categorical_plot

# to visually compare the distribution of time values across different conditions and levels of block. and to identify any outliers or extreme values in the data distribution for each condition and level of block.

ggsave("lmm_categorical_plot.pdf", plot = lmm_categorical_plot, dpi = 600)
```


```{r}
#Mean trial times per participant by condition
lmm_plot_perparticipant <- grasping_data %>%
  group_by(participant_id, condition) %>%
  summarize(mean_time = mean(time)) %>%
  ggplot(aes(x = condition, y = mean_time, fill = condition)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Mean trial times by condition",
    x = "Condition Type",
    y = "Mean trial times (ms) \n"
  ) +
  facet_wrap(~participant_id, scales = "free") +  # Facet by participant_id
  theme_linedraw() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    legend.position = "right",
    legend.title = element_blank(), strip.text = element_text(size = 5), axis.title = element_text(size = 5),
    axis.text = element_text(size = 5),  axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14)
  ) +
  scale_y_continuous(limits = c(0000, 12000))

lmm_plot_perparticipant

ggsave("lmm_plot_perparticipant.png", plot = lmm_plot_perparticipant, width = 8, height = 6, units = "in", dpi = 600)

```


```{r}
lmm_plot_block <- grasping_data %>%
  group_by(block, condition) %>%
  summarize(mean_time = mean(time)) %>%
  ggplot(aes(x = block, y = mean_time, color = condition, shape = condition)) +
  geom_point(size = 4) +
  labs(
    title = "Mean Trial Times per Block by Condition",
    x = "\nBlock Number",
    y = "Mean Trial Times (ms)\n",
    color = "Condition", 
    shape = "Condition" 
  ) +
  facet_wrap(~block, scales = "free", labeller = labeller(block = function(x) paste("Block", x))) +
  theme_minimal() + 
  theme(plot.title = element_text(face = "bold"),
        legend.position = "right",
        legend.title = element_text(face = "bold")) + # Bold legend title
  scale_y_continuous(limits = c(2000, 6000))

lmm_plot_block

ggsave("lmm_plot_block.pdf", plot = lmm_plot_block, dpi = 600)

```


```{r, eval=FALSE}
# Extract fixed (and random) effects
fixed_effects <- fixef(model_final)
#random_effects_exp <- ranef(model)$experimenter
#random_effects_order <- ranef(model)$order

# create dfs
fixed_effects_df <- data.frame(variable = names(fixed_effects), value = fixed_effects)
fixed_effects_df$value[1] <- fixed_effects_df$value[1]
fixed_effects_df$value[2] <- fixed_effects_df$value[1] + fixed_effects_df$value[2]
fixed_effects_df$value[3] <- fixed_effects_df$value[1] + fixed_effects_df$value[3]
fixed_effects_df$value[4] <- fixed_effects_df$value[1] + fixed_effects_df$value[4]

fixed_effects_df

# Define the desired order of levels for the variable
order <- c("(Intercept)", "conditiontactile", "block2", "block3")
fixed_effects_df$variable <- factor(fixed_effects_df$variable, levels = order)

# Plot fixed effects with a regression line
lmm_fix <- ggplot(fixed_effects_df, aes(x = variable, y = value)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "#FFCC66") +
  geom_line(group = 1, color = "#FFCC66") +  # Connect points with a line
  labs(title = "Condition and block effects on trial time", x = NULL, y = "Trial time (ms) \n",) +
  scale_x_discrete(labels = c("Condition Auditory", "Block2", "Block3", "Condition Tactile")) +
  theme_minimal()

lmm_fix

ggsave("lmm_fixed.pdf", plot = lmm_fix, dpi = 600)
```

### LMM diagnostics

```{r, eval=FALSE}
# Independence & Homoscedasticity
plot(fitted(model_final), resid(model_final), ylab = "Residuals", xlab = "Fitted Values")
abline(h = 0, col = "red", lty = 2)
#Purpose: This code creates a plot to check for independence and homoscedasticity of residuals, helping to assess whether residuals are evenly distributed around zero (homoscedasticity) and whether there's any pattern or trend in the residuals (independence)

# Normality of residuals
qqnorm(resid(model_final))
qqline(resid(model_final))
hist(resid(model_final), main = "Histogram of Residuals")
shapiro.test(resid(model_final))
#assesses the normality of residuals, result:he test resulted in a very low p-value (< 2.2e-16), indicating strong evidence against the null hypothesis of normality.Therefore, based on this test, the assumption of normality for residuals is violated.

# No Perfect Multicollinearity
# No multicollinearity. The variance of the regression coefficient is not inflated.

# Ranef structure
summary(model_final)
```

